{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from pandas import read_parquet\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            vocab_size, embedding_dim, \n",
    "            lstm_hidden_dim, lstm_num_layers, lstm_dropout, \n",
    "            linear_output_dim, label_size\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=lstm_hidden_dim,\n",
    "            num_layers=lstm_num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=lstm_dropout,\n",
    "            # no use of dropout with only one layer\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.fc1 = nn.Linear(2 * lstm_hidden_dim, linear_output_dim)\n",
    "        self.dropout = nn.Dropout(lstm_dropout)\n",
    "        self.fc2 = nn.Linear(linear_output_dim, label_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(F.elu(self.fc1(x), inplace=True))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_parquet(\"data/merge/train.parquet\").sample(5000)\n",
    "dev_data = read_parquet(\"data/merge/dev.parquet\").sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_data[\"tokens\"].values.tolist()\n",
    "train_tags = train_data[\"ner_tags\"].values.tolist()\n",
    "dev_text = dev_data[\"tokens\"].values.tolist()\n",
    "dev_tags = dev_data[\"ner_tags\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mappings(train_text):\n",
    "    train_words = set([word for sentence in train_text for word in sentence])\n",
    "    word2idx = {word: idx + 2 for idx, word in enumerate(train_words)}\n",
    "    word2idx['<pad>'] = 0  # use <pad> for padding word\n",
    "    word2idx['<unk>'] = 1   # use <unk> for unknown words and low frequency words\n",
    "    return word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = generate_mappings(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomizedDataset(Dataset):\n",
    "    def __init__(self, word2idx, sentences, labels) -> None:\n",
    "        super().__init__()\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.word2idx = word2idx\n",
    "        self.numerize()\n",
    "\n",
    "    def numerize(self):\n",
    "        self.num_data = []\n",
    "        for sentence in self.sentences:\n",
    "            num_words = [self.word2idx.get(word, self.word2idx['<unk>']) for word in sentence]\n",
    "            self.num_data.append(num_words)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        word_seq = self.num_data[index]\n",
    "        tag_seq = self.labels[index]\n",
    "        return torch.tensor(word_seq), torch.tensor(tag_seq)\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    word_seqs, tag_seqs = zip(*batch)\n",
    "    word_seqs = pad_sequence(word_seqs, batch_first=True, padding_value=0)\n",
    "    tag_seqs = pad_sequence(tag_seqs, batch_first=True, padding_value=9)\n",
    "    return word_seqs, tag_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomizedDataset(word2idx, train_text, train_tags)\n",
    "dev_dataset = CustomizedDataset(word2idx, dev_text, dev_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 32\n",
    "DEV_BATCH_SIZE = 16\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "dev_loader = DataLoader(\n",
    "    dataset=dev_dataset,\n",
    "    batch_size=DEV_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx)\n",
    "label_size = 10\n",
    "embedding_dim = 100\n",
    "lstm_num_layers = 2\n",
    "lstm_hidden_dim = 256\n",
    "lstm_dropout = 0.33\n",
    "linear_output_dim = 128\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = BiLSTM(vocab_size, embedding_dim, lstm_hidden_dim, lstm_num_layers, lstm_dropout, linear_output_dim, label_size)\n",
    "optimizer = Adam(model.parameters(), lr=3e-3, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=9) \n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:25<00:00,  6.10it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.5235, train_acc: 0.8287, val_loss: 0.6546, val_acc: 0.7887\n",
      "val_precision: 0.7268, val_recall: 0.5894, val_f1: 0.6153\n",
      "Epoch: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:28<00:00,  5.53it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.3858, train_acc: 0.8742, val_loss: 0.7745, val_acc: 0.7552\n",
      "val_precision: 0.6259, val_recall: 0.6529, val_f1: 0.6245\n",
      "Epoch: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:29<00:00,  5.34it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.3213, train_acc: 0.8938, val_loss: 0.6637, val_acc: 0.7951\n",
      "val_precision: 0.6661, val_recall: 0.6649, val_f1: 0.6608\n",
      "Epoch: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:27<00:00,  5.71it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.2402, train_acc: 0.9196, val_loss: 0.6631, val_acc: 0.8151\n",
      "val_precision: 0.7001, val_recall: 0.6733, val_f1: 0.6818\n",
      "Epoch: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:37<00:00,  4.24it/s]\n",
      "100%|██████████| 63/63 [00:04<00:00, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.2250, train_acc: 0.9255, val_loss: 0.6271, val_acc: 0.8154\n",
      "val_precision: 0.6868, val_recall: 0.6785, val_f1: 0.6790\n",
      "Epoch: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:29<00:00,  5.24it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1950, train_acc: 0.9370, val_loss: 0.7061, val_acc: 0.7957\n",
      "val_precision: 0.6729, val_recall: 0.6804, val_f1: 0.6718\n",
      "Epoch: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:30<00:00,  5.14it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 20.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1761, train_acc: 0.9422, val_loss: 0.6991, val_acc: 0.8258\n",
      "val_precision: 0.7241, val_recall: 0.6627, val_f1: 0.6900\n",
      "Epoch: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:26<00:00,  6.02it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1491, train_acc: 0.9514, val_loss: 0.7092, val_acc: 0.8182\n",
      "val_precision: 0.7003, val_recall: 0.6886, val_f1: 0.6917\n",
      "Epoch: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:27<00:00,  5.75it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1490, train_acc: 0.9516, val_loss: 0.7153, val_acc: 0.8222\n",
      "val_precision: 0.7135, val_recall: 0.6811, val_f1: 0.6957\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:27<00:00,  5.80it/s]\n",
      "100%|██████████| 63/63 [00:03<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.1325, train_acc: 0.9584, val_loss: 0.7351, val_acc: 0.8293\n",
      "val_precision: 0.7275, val_recall: 0.6887, val_f1: 0.7028\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "best_f1 = 0\n",
    "# best_loss = torch.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch + 1}/{epochs}')\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    amount = 0\n",
    "    model.train()\n",
    "    for data, target in tqdm(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data)\n",
    "        pred = pred.view(-1, label_size)\n",
    "        target = target.view(-1)\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.cpu().item() * data.shape[0]\n",
    "        target = target.cpu()\n",
    "        pred = torch.argmax(pred, dim=1).cpu()\n",
    "        mask = target != 9\n",
    "        masked_pred = pred[mask]\n",
    "        masked_target = target[mask]\n",
    "        correct += sum(masked_pred == masked_target)\n",
    "        amount += sum(mask)\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    train_acc = correct / amount\n",
    "\n",
    "    val_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "    correct = 0\n",
    "    amount = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(dev_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            pred = model(data)\n",
    "            pred = pred.view(-1, label_size)\n",
    "            target = target.view(-1)\n",
    "            loss = criterion(pred, target)\n",
    "\n",
    "            val_loss += loss.cpu().item() * data.shape[0]\n",
    "\n",
    "            target = target.cpu()\n",
    "            pred = torch.argmax(pred, dim=1).cpu()\n",
    "            mask = target != 9\n",
    "            masked_pred = pred[mask]\n",
    "            masked_target = target[mask]\n",
    "            correct += sum(masked_pred == masked_target)\n",
    "            amount += sum(mask)\n",
    "            y_pred.extend(masked_pred)\n",
    "            y_true.extend(masked_target)\n",
    "\n",
    "    val_loss /= len(dev_dataset)\n",
    "    val_acc = correct / amount\n",
    "    val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
    "    print('train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}'.format(train_loss, train_acc, val_loss, val_acc))\n",
    "    print('val_precision: {:.4f}, val_recall: {:.4f}, val_f1: {:.4f}'.format(val_precision, val_recall, val_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
