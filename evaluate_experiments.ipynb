{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\annaconda3\\envs\\nlp1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from pandas import read_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_parquet(\"data/merge/train.parquet\")\n",
    "dev_data = read_parquet(\"data/merge/dev.parquet\")\n",
    "test_data = read_parquet(\"data/merge/test.parquet\")\n",
    "\n",
    "with open(\"data/merge/tags_2_idx.json\", \"r\") as f:\n",
    "    tags2idx = json.load(f)\n",
    "\n",
    "idx2tags = {idx: tag for tag, idx in tags2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tags = dev_data[\"ner_tags\"].values.tolist()\n",
    "dev_tags = [x.tolist() for x in dev_tags]\n",
    "dev_tags = [[idx2tags[idx] for idx in tags] for tags in dev_tags]\n",
    "\n",
    "test_tags = test_data[\"ner_tags\"].values.tolist()\n",
    "test_tags = [x.tolist() for x in test_tags]\n",
    "test_tags = [[idx2tags[idx] for idx in tags] for tags in test_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = \"model_prediction_files\"\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.7927988083620114,\n",
       "  'recall': 0.8008197571858462,\n",
       "  'f1': 0.7967890973853341,\n",
       "  'number': 19274},\n",
       " 'ORG': {'precision': 0.6547136756815942,\n",
       "  'recall': 0.7437189054726369,\n",
       "  'f1': 0.6963838583823444,\n",
       "  'number': 16080},\n",
       " 'PER': {'precision': 0.8282334480053111,\n",
       "  'recall': 0.8289338568408335,\n",
       "  'f1': 0.8285835044076801,\n",
       "  'number': 16555},\n",
       " 'overall_precision': 0.7571633765468474,\n",
       " 'overall_recall': 0.7920977094530813,\n",
       " 'overall_f1': 0.77423667535989,\n",
       " 'overall_accuracy': 0.9060073944565635}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_result = pd.read_csv(result_path + \"/BiLSTM_dev.csv\")\n",
    "dev_predictions = dev_result[\"predictions\"].values.tolist()\n",
    "dev_predictions = [eval(x) for x in dev_predictions]\n",
    "dev_references = []\n",
    "for i in range(len(dev_predictions)):\n",
    "    dev_references.append(dev_tags[i][:len(dev_predictions[i])])\n",
    "dev_result = seqeval.compute(predictions=dev_predictions, references=dev_references)\n",
    "dev_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.7791982000409081,\n",
       "  'recall': 0.7786805662016455,\n",
       "  'f1': 0.7789392971246006,\n",
       "  'number': 19569},\n",
       " 'ORG': {'precision': 0.6256896013323618,\n",
       "  'recall': 0.7112767719796473,\n",
       "  'f1': 0.6657437146970872,\n",
       "  'number': 16902},\n",
       " 'PER': {'precision': 0.8182443272977309,\n",
       "  'recall': 0.8302325581395349,\n",
       "  'f1': 0.8241948516680134,\n",
       "  'number': 17200},\n",
       " 'overall_precision': 0.7388566753228274,\n",
       " 'overall_recall': 0.7739747722233609,\n",
       " 'overall_f1': 0.7560081169865231,\n",
       " 'overall_accuracy': 0.9041126316132109}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = pd.read_csv(result_path + \"/BiLSTM_test.csv\")\n",
    "test_predictions = test_result[\"predictions\"].values.tolist()\n",
    "test_predictions = [eval(x) for x in test_predictions]\n",
    "test_references = []\n",
    "for i in range(len(test_predictions)):\n",
    "    test_references.append(test_tags[i][:len(test_predictions[i])])\n",
    "test_result = seqeval.compute(predictions=test_predictions, references=test_references)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM + CharCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.7975469489541452,\n",
       "  'recall': 0.8130642316073466,\n",
       "  'f1': 0.8052308403771548,\n",
       "  'number': 19274},\n",
       " 'ORG': {'precision': 0.6985315798785162,\n",
       "  'recall': 0.7366293532338308,\n",
       "  'f1': 0.7170747949269001,\n",
       "  'number': 16080},\n",
       " 'PER': {'precision': 0.8134045485871813,\n",
       "  'recall': 0.8555119299305346,\n",
       "  'f1': 0.8339270468395795,\n",
       "  'number': 16555},\n",
       " 'overall_precision': 0.771576141286238,\n",
       " 'overall_recall': 0.8029243483788938,\n",
       " 'overall_f1': 0.7869381744031267,\n",
       " 'overall_accuracy': 0.9068956114461696}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_result = pd.read_csv(result_path + \"/BiLSTM_CNN_dev.csv\")\n",
    "dev_predictions = dev_result[\"predictions\"].values.tolist()\n",
    "dev_predictions = [eval(x) for x in dev_predictions]\n",
    "dev_references = []\n",
    "for i in range(len(dev_predictions)):\n",
    "    dev_references.append(dev_tags[i][:len(dev_predictions[i])])\n",
    "dev_result = seqeval.compute(predictions=dev_predictions, references=dev_references)\n",
    "dev_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.7767096677790507,\n",
       "  'recall': 0.7968726046297716,\n",
       "  'f1': 0.7866619583312314,\n",
       "  'number': 19569},\n",
       " 'ORG': {'precision': 0.6679731879118382,\n",
       "  'recall': 0.6957164832564193,\n",
       "  'f1': 0.6815626267895438,\n",
       "  'number': 16902},\n",
       " 'PER': {'precision': 0.8112227990721308,\n",
       "  'recall': 0.8539534883720931,\n",
       "  'f1': 0.8320398799070979,\n",
       "  'number': 17200},\n",
       " 'overall_precision': 0.7535985086131177,\n",
       " 'overall_recall': 0.783309422220566,\n",
       " 'overall_f1': 0.7681667854336822,\n",
       " 'overall_accuracy': 0.9059699120568137}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = pd.read_csv(result_path + \"/BiLSTM_CNN_test.csv\")\n",
    "test_predictions = test_result[\"predictions\"].values.tolist()\n",
    "test_predictions = [eval(x) for x in test_predictions]\n",
    "test_references = []\n",
    "for i in range(len(test_predictions)):\n",
    "    test_references.append(test_tags[i][:len(test_predictions[i])])\n",
    "test_result = seqeval.compute(predictions=test_predictions, references=test_references)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CharCNN + Attention (Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.7457205559619605,\n",
       "  'recall': 0.7933485524540832,\n",
       "  'f1': 0.7687976067774455,\n",
       "  'number': 19274},\n",
       " 'ORG': {'precision': 0.6221147504946142,\n",
       "  'recall': 0.7039800995024875,\n",
       "  'f1': 0.660520480802894,\n",
       "  'number': 16080},\n",
       " 'PER': {'precision': 0.7863664719559916,\n",
       "  'recall': 0.8375717305949865,\n",
       "  'f1': 0.8111618111618112,\n",
       "  'number': 16555},\n",
       " 'overall_precision': 0.7185181240458692,\n",
       " 'overall_recall': 0.7797684409254657,\n",
       " 'overall_f1': 0.7478913186072078,\n",
       " 'overall_accuracy': 0.9060535095598614}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_result = pd.read_csv(result_path + \"/BiLSTM_CNN_Attention_dev.csv\")\n",
    "dev_predictions = dev_result[\"predictions\"].values.tolist()\n",
    "dev_predictions = [eval(x) for x in dev_predictions]\n",
    "dev_references = []\n",
    "for i in range(len(dev_predictions)):\n",
    "    dev_references.append(dev_tags[i][:len(dev_predictions[i])])\n",
    "dev_result = seqeval.compute(predictions=dev_predictions, references=dev_references)\n",
    "dev_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.7301221036438804,\n",
       "  'recall': 0.7761255046246615,\n",
       "  'f1': 0.7524212925119517,\n",
       "  'number': 19569},\n",
       " 'ORG': {'precision': 0.6006036217303823,\n",
       "  'recall': 0.6711040113596024,\n",
       "  'f1': 0.6338996311612831,\n",
       "  'number': 16902},\n",
       " 'PER': {'precision': 0.7724093403637147,\n",
       "  'recall': 0.8346511627906976,\n",
       "  'f1': 0.8023249315374728,\n",
       "  'number': 17200},\n",
       " 'overall_precision': 0.7016336616672959,\n",
       " 'overall_recall': 0.7618080527659258,\n",
       " 'overall_f1': 0.7304837196837732,\n",
       " 'overall_accuracy': 0.9040915696700359}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = pd.read_csv(result_path + \"/BiLSTM_CNN_Attention_test.csv\")\n",
    "test_predictions = test_result[\"predictions\"].values.tolist()\n",
    "test_predictions = [eval(x) for x in test_predictions]\n",
    "test_references = []\n",
    "for i in range(len(test_predictions)):\n",
    "    test_references.append(test_tags[i][:len(test_predictions[i])])\n",
    "test_result = seqeval.compute(predictions=test_predictions, references=test_references)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM + CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.8778469058993446,\n",
       "  'recall': 0.8199128359447961,\n",
       "  'f1': 0.8478914046571521,\n",
       "  'number': 19274},\n",
       " 'ORG': {'precision': 0.7683598716473936,\n",
       "  'recall': 0.7892412935323383,\n",
       "  'f1': 0.778660612939841,\n",
       "  'number': 16080},\n",
       " 'PER': {'precision': 0.9007547169811321,\n",
       "  'recall': 0.8651162790697674,\n",
       "  'f1': 0.8825758742874749,\n",
       "  'number': 16555},\n",
       " 'overall_precision': 0.8492036732184296,\n",
       " 'overall_recall': 0.824828064497486,\n",
       " 'overall_f1': 0.8368384020014072,\n",
       " 'overall_accuracy': 0.9023663063005262}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_result = pd.read_csv(result_path + \"/BiLSTM_CRF_dev.csv\")\n",
    "dev_predictions = dev_result[\"predictions\"].values.tolist()\n",
    "dev_predictions = [eval(x) for x in dev_predictions]\n",
    "dev_references = []\n",
    "for i in range(len(dev_predictions)):\n",
    "    dev_references.append(dev_tags[i][:len(dev_predictions[i])])\n",
    "dev_result = seqeval.compute(predictions=dev_predictions, references=dev_references)\n",
    "dev_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.8680806752164858,\n",
       "  'recall': 0.8093924063569932,\n",
       "  'f1': 0.8377099034774559,\n",
       "  'number': 19569},\n",
       " 'ORG': {'precision': 0.748600388944546,\n",
       "  'recall': 0.7515678617915039,\n",
       "  'f1': 0.7500811903988662,\n",
       "  'number': 16902},\n",
       " 'PER': {'precision': 0.8839637274788211,\n",
       "  'recall': 0.861453488372093,\n",
       "  'f1': 0.8725634532713031,\n",
       "  'number': 17200},\n",
       " 'overall_precision': 0.8341958943378802,\n",
       " 'overall_recall': 0.8078664455665071,\n",
       " 'overall_f1': 0.8208200817810086,\n",
       " 'overall_accuracy': 0.9026153189256877}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = pd.read_csv(result_path + \"/BiLSTM_CRF_test.csv\")\n",
    "test_predictions = test_result[\"predictions\"].values.tolist()\n",
    "test_predictions = [eval(x) for x in test_predictions]\n",
    "test_references = []\n",
    "for i in range(len(test_predictions)):\n",
    "    test_references.append(test_tags[i][:len(test_predictions[i])])\n",
    "test_result = seqeval.compute(predictions=test_predictions, references=test_references)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention + CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.8439826647405267,\n",
       "  'recall': 0.7881083324686106,\n",
       "  'f1': 0.8150890749087787,\n",
       "  'number': 19274},\n",
       " 'ORG': {'precision': 0.7308071559374559,\n",
       "  'recall': 0.645273631840796,\n",
       "  'f1': 0.6853821256357752,\n",
       "  'number': 16080},\n",
       " 'PER': {'precision': 0.8187373917170998,\n",
       "  'recall': 0.8335246149199638,\n",
       "  'f1': 0.8260648328294771,\n",
       "  'number': 16555},\n",
       " 'overall_precision': 0.8025484199796127,\n",
       " 'overall_recall': 0.7583463368587335,\n",
       " 'overall_f1': 0.7798215117027705,\n",
       " 'overall_accuracy': 0.8665569260875144}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_result = pd.read_csv(result_path + \"/ATTENTION_CRF_dev.csv\")\n",
    "dev_predictions = dev_result[\"predictions\"].values.tolist()\n",
    "dev_predictions = [eval(x) for x in dev_predictions]\n",
    "dev_references = []\n",
    "for i in range(len(dev_predictions)):\n",
    "    dev_references.append(dev_tags[i][:len(dev_predictions[i])])\n",
    "dev_result = seqeval.compute(predictions=dev_predictions, references=dev_references)\n",
    "dev_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.827580530099325,\n",
       "  'recall': 0.7706576728499157,\n",
       "  'f1': 0.7981054191363252,\n",
       "  'number': 19569},\n",
       " 'ORG': {'precision': 0.709853392430958,\n",
       "  'recall': 0.6159034433794817,\n",
       "  'f1': 0.6595495295720214,\n",
       "  'number': 16902},\n",
       " 'PER': {'precision': 0.808072255151002,\n",
       "  'recall': 0.8322674418604651,\n",
       "  'f1': 0.819991407704425,\n",
       "  'number': 17200},\n",
       " 'overall_precision': 0.786633203565006,\n",
       " 'overall_recall': 0.7416668219336326,\n",
       " 'overall_f1': 0.7634885014481079,\n",
       " 'overall_accuracy': 0.8690789612249626}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = pd.read_csv(result_path + \"/ATTENTION_CRF_test.csv\")\n",
    "test_predictions = test_result[\"predictions\"].values.tolist()\n",
    "test_predictions = [eval(x) for x in test_predictions]\n",
    "test_references = []\n",
    "for i in range(len(test_predictions)):\n",
    "    test_references.append(test_tags[i][:len(test_predictions[i])])\n",
    "test_result = seqeval.compute(predictions=test_predictions, references=test_references)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention (Encoder) + CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.8261148883773222,\n",
       "  'recall': 0.800612223721075,\n",
       "  'f1': 0.8131636497773562,\n",
       "  'number': 19274},\n",
       " 'ORG': {'precision': 0.7881140598531903,\n",
       "  'recall': 0.6944029850746268,\n",
       "  'f1': 0.7382967468923566,\n",
       "  'number': 16080},\n",
       " 'PER': {'precision': 0.8471808320419597,\n",
       "  'recall': 0.8585925702204772,\n",
       "  'f1': 0.8528485284852848,\n",
       "  'number': 16555},\n",
       " 'overall_precision': 0.8223879093198992,\n",
       " 'overall_recall': 0.7862027779383152,\n",
       " 'overall_f1': 0.8038883526700417,\n",
       " 'overall_accuracy': 0.8892275118696266}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_result = pd.read_csv(result_path + \"/Attention_Encoder_CRF_dev.csv\")\n",
    "dev_predictions = dev_result[\"predictions\"].values.tolist()\n",
    "dev_predictions = [eval(x) for x in dev_predictions]\n",
    "dev_references = []\n",
    "for i in range(len(dev_predictions)):\n",
    "    dev_references.append(dev_tags[i][:len(dev_predictions[i])])\n",
    "dev_result = seqeval.compute(predictions=dev_predictions, references=dev_references)\n",
    "dev_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.8056837248322147,\n",
       "  'recall': 0.7852215238387246,\n",
       "  'f1': 0.7953210320643876,\n",
       "  'number': 19569},\n",
       " 'ORG': {'precision': 0.7616485013623978,\n",
       "  'recall': 0.6615193468228612,\n",
       "  'f1': 0.7080615540497751,\n",
       "  'number': 16902},\n",
       " 'PER': {'precision': 0.840104998858708,\n",
       "  'recall': 0.8559302325581395,\n",
       "  'f1': 0.8479437852781937,\n",
       "  'number': 17200},\n",
       " 'overall_precision': 0.8048404711755988,\n",
       " 'overall_recall': 0.7689254904883457,\n",
       " 'overall_f1': 0.7864731721726205,\n",
       " 'overall_accuracy': 0.889286938340204}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = pd.read_csv(result_path + \"/Attention_Encoder_CRF_test.csv\")\n",
    "test_predictions = test_result[\"predictions\"].values.tolist()\n",
    "test_predictions = [eval(x) for x in test_predictions]\n",
    "test_references = []\n",
    "for i in range(len(test_predictions)):\n",
    "    test_references.append(test_tags[i][:len(test_predictions[i])])\n",
    "test_result = seqeval.compute(predictions=test_predictions, references=test_references)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.7254286909242994,\n",
       "  'recall': 0.7199335892912733,\n",
       "  'f1': 0.7226706942346751,\n",
       "  'number': 19274},\n",
       " 'ORG': {'precision': 0.5612784204228161,\n",
       "  'recall': 0.7000621890547264,\n",
       "  'f1': 0.6230352003542174,\n",
       "  'number': 16080},\n",
       " 'PER': {'precision': 0.770806432679892,\n",
       "  'recall': 0.7932950770160072,\n",
       "  'f1': 0.7818890840353646,\n",
       "  'number': 16555},\n",
       " 'overall_precision': 0.6806232435701327,\n",
       " 'overall_recall': 0.7371746710589686,\n",
       " 'overall_f1': 0.7077711294633362,\n",
       " 'overall_accuracy': 0.8871142371358912}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_result = pd.read_csv(result_path + \"/Channel_dev.csv\")\n",
    "dev_predictions = dev_result[\"predictions\"].values.tolist()\n",
    "dev_predictions = [eval(x) for x in dev_predictions]\n",
    "dev_references = []\n",
    "for i in range(len(dev_predictions)):\n",
    "    dev_references.append(dev_tags[i][:len(dev_predictions[i])])\n",
    "dev_result = seqeval.compute(predictions=dev_predictions, references=dev_references)\n",
    "dev_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.6968503937007874,\n",
       "  'recall': 0.6964586846543002,\n",
       "  'f1': 0.6966544841158279,\n",
       "  'number': 19569},\n",
       " 'ORG': {'precision': 0.5338313665778455,\n",
       "  'recall': 0.663767601467282,\n",
       "  'f1': 0.5917506197584261,\n",
       "  'number': 16902},\n",
       " 'PER': {'precision': 0.7674640610961365,\n",
       "  'recall': 0.7945930232558139,\n",
       "  'f1': 0.780792961608775,\n",
       "  'number': 17200},\n",
       " 'overall_precision': 0.6597067589325477,\n",
       " 'overall_recall': 0.7176128635576009,\n",
       " 'overall_f1': 0.6874425495078221,\n",
       " 'overall_accuracy': 0.8855972688403868}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = pd.read_csv(result_path + \"/Channel_test.csv\")\n",
    "test_predictions = test_result[\"predictions\"].values.tolist()\n",
    "test_predictions = [eval(x) for x in test_predictions]\n",
    "test_references = []\n",
    "for i in range(len(test_predictions)):\n",
    "    test_references.append(test_tags[i][:len(test_predictions[i])])\n",
    "test_result = seqeval.compute(predictions=test_predictions, references=test_references)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilated CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.6770175121863152,\n",
       "  'recall': 0.7782504928919788,\n",
       "  'f1': 0.724112961622013,\n",
       "  'number': 19274},\n",
       " 'ORG': {'precision': 0.5287422037422037,\n",
       "  'recall': 0.6326492537313433,\n",
       "  'f1': 0.5760475651189128,\n",
       "  'number': 16080},\n",
       " 'PER': {'precision': 0.6784286630804915,\n",
       "  'recall': 0.8303835699184536,\n",
       "  'f1': 0.7467543049595307,\n",
       "  'number': 16555},\n",
       " 'overall_precision': 0.6312136103407451,\n",
       " 'overall_recall': 0.7497736423356258,\n",
       " 'overall_f1': 0.685404339250493,\n",
       " 'overall_accuracy': 0.9023121711792634}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_result = pd.read_csv(result_path + \"/DCNN_dev.csv\")\n",
    "dev_predictions = dev_result[\"predictions\"].values.tolist()\n",
    "dev_predictions = [eval(x) for x in dev_predictions]\n",
    "dev_references = []\n",
    "for i in range(len(dev_predictions)):\n",
    "    dev_references.append(dev_tags[i][:len(dev_predictions[i])])\n",
    "dev_result = seqeval.compute(predictions=dev_predictions, references=dev_references)\n",
    "dev_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.6582594964470567,\n",
       "  'recall': 0.7668761817159794,\n",
       "  'f1': 0.7084287299077112,\n",
       "  'number': 19569},\n",
       " 'ORG': {'precision': 0.5075318066157761,\n",
       "  'recall': 0.5900485149686427,\n",
       "  'f1': 0.5456883344276647,\n",
       "  'number': 16902},\n",
       " 'PER': {'precision': 0.6760729816600491,\n",
       "  'recall': 0.8315697674418605,\n",
       "  'f1': 0.7458024820106373,\n",
       "  'number': 17200},\n",
       " 'overall_precision': 0.6176183887805798,\n",
       " 'overall_recall': 0.7319222671461311,\n",
       " 'overall_f1': 0.6699296525261139,\n",
       " 'overall_accuracy': 0.9019221895230236}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = pd.read_csv(result_path + \"/DCNN_test.csv\")\n",
    "test_predictions = test_result[\"predictions\"].values.tolist()\n",
    "test_predictions = [eval(x) for x in test_predictions]\n",
    "test_references = []\n",
    "for i in range(len(test_predictions)):\n",
    "    test_references.append(test_tags[i][:len(test_predictions[i])])\n",
    "test_result = seqeval.compute(predictions=test_predictions, references=test_references)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKWEAK Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "skweak_tags2tags = {\n",
    "    \"BLOC\": \"B-LOC\",\n",
    "    \"ILOC\": \"I-LOC\",\n",
    "    \"BPER\": \"B-PER\", \n",
    "    \"IPER\": \"I-PER\",\n",
    "    \"BORG\": \"B-ORG\",\n",
    "    \"IORG\": \"I-ORG\",\n",
    "    \"BMISC\": \"B-MISC\",\n",
    "    \"IMISC\": \"I-MISC\",\n",
    "    \"O\": \"O\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM & BiLSTM + CharCNN & BiLSTM + CRF & Attention (Encoder) + CharCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.8439731316443645,\n",
       "  'recall': 0.8279028743384871,\n",
       "  'f1': 0.835860768445038,\n",
       "  'number': 19274},\n",
       " 'ORG': {'precision': 0.772856221792392,\n",
       "  'recall': 0.7453211465522601,\n",
       "  'f1': 0.7588389833190896,\n",
       "  'number': 16083},\n",
       " 'PER': {'precision': 0.8804778371581263,\n",
       "  'recall': 0.8459075807913017,\n",
       "  'f1': 0.8628465804066543,\n",
       "  'number': 16555},\n",
       " 'overall_precision': 0.8335916696474703,\n",
       " 'overall_recall': 0.8080597934966867,\n",
       " 'overall_f1': 0.8206271886065301,\n",
       " 'overall_accuracy': 0.9096865110264607}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_result = pd.read_csv(\"skweak/skweak_hmm_output.csv\")\n",
    "dev_predictions = dev_result[\"predictions\"].values.tolist()\n",
    "dev_predictions = [eval(x) for x in dev_predictions]\n",
    "dev_predictions = [[skweak_tags2tags[x] for x in tags] for tags in dev_predictions]\n",
    "\n",
    "dev_references = []\n",
    "for i in range(len(dev_predictions)):\n",
    "    dev_references.append(dev_tags[i][:len(dev_predictions[i])])\n",
    "dev_result = seqeval.compute(predictions=dev_predictions, references=dev_references)\n",
    "dev_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
