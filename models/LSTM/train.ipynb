{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_JA = read_parquet(\"../../data/japan/test-00000-of-00001.parquet\")\n",
    "data_test_SP = read_parquet(\"../../data/spain/test-00000-of-00001.parquet\")\n",
    "data_test_CH = read_parquet(\"../../data/china/test-00000-of-00001.parquet\")\n",
    "data_test_FR = read_parquet(\"../../data/france/test-00000-of-00001.parquet\")\n",
    "data_train_EN = read_parquet(\"../../data/english/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "519\n"
     ]
    }
   ],
   "source": [
    "data_train_EN.iloc[1721]['tokens'].tolist()\n",
    "\n",
    "encoded_input_wo_pad = tokenizer(data_train_EN.iloc[1721]['tokens'].tolist(), return_tensors='pt',is_split_into_words=True)\n",
    "print(len(encoded_input_wo_pad.word_ids()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>langs</th>\n",
       "      <th>spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[R.H., Saunders, (, St., Lawrence, River, ), (...</td>\n",
       "      <td>[3, 4, 0, 3, 4, 4, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en, en]</td>\n",
       "      <td>[ORG: R.H. Saunders, ORG: St. Lawrence River]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[;, ', '', Anders, Lindström, '', ']</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en]</td>\n",
       "      <td>[PER: Anders Lindström]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Karl, Ove, Knausgård, (, born, 1968, )]</td>\n",
       "      <td>[1, 2, 2, 0, 0, 0, 0]</td>\n",
       "      <td>[en, en, en, en, en, en, en]</td>\n",
       "      <td>[PER: Karl Ove Knausgård]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Atlantic, City, ,, New, Jersey]</td>\n",
       "      <td>[5, 6, 6, 6, 6]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "      <td>[LOC: Atlantic City , New Jersey]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Her, daughter, from, the, second, marriage, w...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[en, en, en, en, en, en, en, en, en, en, en, e...</td>\n",
       "      <td>[PER: Marie d'Agoult, PER: Franz Liszt, PER: C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>[Cicely, Courtneidge, ,, Ernest, Truex]</td>\n",
       "      <td>[1, 2, 0, 1, 2]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "      <td>[PER: Cicely Courtneidge, PER: Ernest Truex]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>[Aracaju, ,, Sergipe, ,, Brazil]</td>\n",
       "      <td>[5, 0, 5, 0, 5]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "      <td>[LOC: Aracaju, LOC: Sergipe, LOC: Brazil]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>[Louisville, in, the, American, Civil, War]</td>\n",
       "      <td>[5, 6, 6, 6, 6, 6]</td>\n",
       "      <td>[en, en, en, en, en, en]</td>\n",
       "      <td>[LOC: Louisville in the American Civil War]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>[16, (, David, Nugent, )]</td>\n",
       "      <td>[0, 0, 1, 2, 0]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "      <td>[PER: David Nugent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>[List, of, regional, mammals, lists]</td>\n",
       "      <td>[3, 4, 4, 4, 4]</td>\n",
       "      <td>[en, en, en, en, en]</td>\n",
       "      <td>[ORG: List of regional mammals lists]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [R.H., Saunders, (, St., Lawrence, River, ), (...   \n",
       "1                   [;, ', '', Anders, Lindström, '', ']   \n",
       "2               [Karl, Ove, Knausgård, (, born, 1968, )]   \n",
       "3                       [Atlantic, City, ,, New, Jersey]   \n",
       "4      [Her, daughter, from, the, second, marriage, w...   \n",
       "...                                                  ...   \n",
       "19995            [Cicely, Courtneidge, ,, Ernest, Truex]   \n",
       "19996                   [Aracaju, ,, Sergipe, ,, Brazil]   \n",
       "19997        [Louisville, in, the, American, Civil, War]   \n",
       "19998                          [16, (, David, Nugent, )]   \n",
       "19999               [List, of, regional, mammals, lists]   \n",
       "\n",
       "                                                ner_tags  \\\n",
       "0                      [3, 4, 0, 3, 4, 4, 0, 0, 0, 0, 0]   \n",
       "1                                  [0, 0, 0, 1, 2, 0, 0]   \n",
       "2                                  [1, 2, 2, 0, 0, 0, 0]   \n",
       "3                                        [5, 6, 6, 6, 6]   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "19995                                    [1, 2, 0, 1, 2]   \n",
       "19996                                    [5, 0, 5, 0, 5]   \n",
       "19997                                 [5, 6, 6, 6, 6, 6]   \n",
       "19998                                    [0, 0, 1, 2, 0]   \n",
       "19999                                    [3, 4, 4, 4, 4]   \n",
       "\n",
       "                                                   langs  \\\n",
       "0           [en, en, en, en, en, en, en, en, en, en, en]   \n",
       "1                           [en, en, en, en, en, en, en]   \n",
       "2                           [en, en, en, en, en, en, en]   \n",
       "3                                   [en, en, en, en, en]   \n",
       "4      [en, en, en, en, en, en, en, en, en, en, en, e...   \n",
       "...                                                  ...   \n",
       "19995                               [en, en, en, en, en]   \n",
       "19996                               [en, en, en, en, en]   \n",
       "19997                           [en, en, en, en, en, en]   \n",
       "19998                               [en, en, en, en, en]   \n",
       "19999                               [en, en, en, en, en]   \n",
       "\n",
       "                                                   spans  \n",
       "0          [ORG: R.H. Saunders, ORG: St. Lawrence River]  \n",
       "1                                [PER: Anders Lindström]  \n",
       "2                              [PER: Karl Ove Knausgård]  \n",
       "3                      [LOC: Atlantic City , New Jersey]  \n",
       "4      [PER: Marie d'Agoult, PER: Franz Liszt, PER: C...  \n",
       "...                                                  ...  \n",
       "19995       [PER: Cicely Courtneidge, PER: Ernest Truex]  \n",
       "19996          [LOC: Aracaju, LOC: Sergipe, LOC: Brazil]  \n",
       "19997        [LOC: Louisville in the American Civil War]  \n",
       "19998                                [PER: David Nugent]  \n",
       "19999              [ORG: List of regional mammals lists]  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R' 'E' 'D' 'I' 'R' 'E' 'C' 'T' '階']\n",
      "tensor([[  101, 15541, 62975, 10228, 10921,   102]])\n",
      "[None, 0, 1, 2, 2, None]\n"
     ]
    }
   ],
   "source": [
    "text = data_test_CH.loc[0, 'tokens'].tolist()\n",
    "print(text)\n",
    "encoded_input_wo_pad = tokenizer([\"text\",\"ff\",\"haha\"], return_tensors='pt',is_split_into_words=True,truncation=True)\n",
    "encoded_input_w_pad = tokenizer([\"text\",\"ff\",\"haha\"], return_tensors='pt',is_split_into_words=True,truncation=True,padding=\"max_length\")\n",
    "print(encoded_input_wo_pad.input_ids)\n",
    "print(encoded_input_wo_pad.word_ids())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'E', 'D', 'I', 'R', 'E', 'C', 'T', '階']\n",
      "{'input_ids': tensor([[ 101,  155,  142,  141,  146,  155,  142,  140,  157, 8244,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]\n"
     ]
    }
   ],
   "source": [
    "sentence_words = data_test_CH['tokens'][0].tolist()\n",
    "print(sentence_words)\n",
    "tokenized_words= tokenizer(sentence_words, return_tensors='pt',is_split_into_words=True,truncation=True)\n",
    "print(tokenized_words)\n",
    "print(tokenized_words.word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(encoded_input_w_pad.token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "output_wo_pad = model(**encoded_input_wo_pad)\n",
    "output_w_pad = model(**encoded_input_w_pad)\n",
    "print(output_wo_pad.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_without_pad=output_wo_pad.last_hidden_state[0][2]\n",
    "out_with_pad=output_w_pad.last_hidden_state[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.4939e-02, -3.7332e-01,  1.4714e+00, -2.6651e-01,  6.9432e-01,\n",
       "        -8.0943e-01, -2.1733e-01, -5.4869e-01,  1.9661e-03,  5.6555e-02,\n",
       "         1.1869e+00, -2.8952e-01,  8.2650e-01,  1.6497e-01, -9.9516e-02,\n",
       "        -2.0574e-01,  3.9803e-01,  2.0877e-01, -5.1269e-01,  8.0204e-01,\n",
       "         1.3882e-02, -6.5385e-01,  1.9936e-01, -2.8387e-01, -1.1863e-01,\n",
       "         3.8612e-01, -6.1916e-01, -9.9126e-02, -4.2922e-01,  1.5927e-01,\n",
       "        -1.1547e-01,  8.1942e-02,  3.1755e-01,  9.3555e-01, -3.3490e-01,\n",
       "         9.7190e-01, -4.2060e-01,  3.0454e-01,  5.9740e-01, -6.7126e-01,\n",
       "        -3.8884e-02,  1.8366e-01, -6.3722e-02,  5.1242e-01,  5.7403e-01,\n",
       "        -9.4466e-01,  1.3993e-01,  1.3399e-01, -1.1592e+00, -1.5897e-01,\n",
       "        -6.7248e-02, -4.6495e-01,  4.0441e-01,  4.9651e-01, -7.1324e-02,\n",
       "         3.9922e-01,  8.6699e-01, -4.6315e-01, -3.1390e-01,  8.2018e-02,\n",
       "         6.9478e-01,  4.9652e-01, -1.7075e-01,  1.9144e-01, -8.3377e-01,\n",
       "        -2.8030e-01,  3.3190e-01,  7.6397e-01,  7.6656e-02, -2.2953e-01,\n",
       "         5.6503e-02,  6.9581e-01,  1.1916e+00, -3.9266e-02,  4.0493e-01,\n",
       "        -8.4311e-03,  8.2035e-01,  3.9105e-01, -1.1516e+00, -4.0403e-01,\n",
       "        -7.5940e-03,  4.5890e-01,  3.0047e-02,  4.4524e-01,  3.1585e-01,\n",
       "        -3.1824e-01, -2.6952e-01, -8.7172e-01,  1.6240e+00, -1.4434e+00,\n",
       "        -7.6283e-02, -5.5162e-01,  2.5323e-01,  4.2161e-01, -6.1248e-01,\n",
       "         8.3636e-01,  4.1840e-01, -4.2681e-01,  2.8491e-01,  2.4610e-01,\n",
       "        -1.6314e-01, -1.6982e-02,  4.4283e-01, -3.8209e-01,  1.2771e+00,\n",
       "         2.4970e-01, -2.6244e-01,  3.3860e-01,  2.8488e-01,  6.0804e-01,\n",
       "         5.5350e-01,  2.5554e-01,  3.6361e-02,  8.8582e-02,  6.3855e-02,\n",
       "        -8.2219e-01, -3.0469e-02, -6.0398e-01, -2.7639e-01, -3.2031e-01,\n",
       "         1.2053e+00,  7.0898e-01,  8.5270e-01, -4.2585e-02,  3.1399e-01,\n",
       "        -3.6841e-01,  4.0634e-01, -3.9704e-01,  1.4111e+00,  7.2566e-01,\n",
       "        -1.2196e-01, -5.3568e-02, -1.6697e-01, -1.1120e-01,  1.4154e-01,\n",
       "         4.0682e-01,  3.6185e-01,  2.2044e-01, -6.1290e-01,  8.3891e-01,\n",
       "        -1.7708e-01,  2.2914e-01,  3.2802e-01, -6.0317e-01, -6.1299e-01,\n",
       "         2.7930e-01, -4.4463e-01,  1.8473e-01,  1.1512e+00, -2.7674e-01,\n",
       "        -3.8810e-01, -3.9538e-02,  1.0832e+00, -5.4126e-01, -7.3279e-01,\n",
       "        -6.2056e-02, -1.3927e-01, -3.2238e-02, -5.7879e-01,  7.6656e-01,\n",
       "         1.7834e-01,  3.6168e-01,  3.8619e-01,  1.7801e+00,  7.3548e-01,\n",
       "        -6.8495e-01,  1.5508e-01, -5.5745e-01, -3.8467e-01, -1.3453e-01,\n",
       "        -5.7889e-02,  4.7564e-01, -5.9979e-01, -3.1326e-01, -1.9019e-01,\n",
       "         7.0046e-01, -3.2208e-01,  1.3043e-02,  2.1787e-01, -8.8628e-02,\n",
       "        -3.3637e-01,  8.7449e-01, -9.5137e-01, -7.2136e-01,  2.8332e-01,\n",
       "         1.6506e-01,  6.1167e-01, -3.2865e-02, -1.0630e+00, -1.9524e-01,\n",
       "         2.6627e-02,  8.6887e-01, -4.9808e-01,  4.2965e-01, -2.4253e-01,\n",
       "         6.5112e-01, -5.9703e-02,  1.1403e-01, -6.8161e-01,  5.7605e-01,\n",
       "        -2.4445e-01, -2.5142e-01,  2.2816e-02, -1.5451e+00, -3.6740e-01,\n",
       "         8.2658e-01,  1.6169e-01, -1.0534e+00,  3.4180e-01,  1.2123e+00,\n",
       "         6.7870e-02, -2.3798e-01,  4.3746e-01,  2.3931e-01, -3.2264e-01,\n",
       "         9.7617e-02,  2.0480e-02,  5.6484e-01, -1.5825e-01,  2.3652e-01,\n",
       "        -3.7909e-01,  1.7329e-01, -1.4397e-01, -1.2495e-01, -4.5082e-01,\n",
       "         2.0271e-01,  3.6900e-02,  2.2263e-01,  8.4403e-01, -4.4974e-01,\n",
       "         3.5838e-01, -3.3074e-01,  3.5240e-01, -8.2257e-01,  1.5435e-02,\n",
       "        -3.5639e-01,  7.1628e-01, -5.0380e-01, -1.0148e-01,  5.3727e-01,\n",
       "         4.1472e-01, -6.0328e-01,  3.2242e-01,  5.3742e-02,  1.2209e-01,\n",
       "         4.7394e-01, -6.7131e-01,  2.4636e-01, -6.1039e-02, -1.6758e+00,\n",
       "         8.1142e-02, -1.1613e-01,  1.5407e-01, -3.4638e-01, -1.4223e+00,\n",
       "        -8.1767e-02, -1.1279e-01,  2.8913e-02,  4.9075e-01, -7.2056e-02,\n",
       "         3.2904e-01, -3.8908e-02, -7.5477e-01,  1.5436e-01, -1.0769e-01,\n",
       "        -5.6938e-01,  3.8283e-01,  2.2583e-01, -4.2754e-01,  4.7989e-01,\n",
       "        -5.7314e-02, -3.2308e-01,  4.5947e-01,  3.2985e-01,  5.7585e-01,\n",
       "        -3.8603e-01,  3.1761e-02,  1.6665e-01,  4.2604e-01,  5.2554e-01,\n",
       "        -2.0305e-01, -9.0319e-02, -7.0820e-01,  8.4840e-01,  6.9282e-03,\n",
       "        -4.9442e-01,  4.6277e-01, -5.7540e-01,  3.6077e-01, -3.8160e-01,\n",
       "         5.0827e-01,  6.1058e-02, -2.5476e-02,  8.5492e-01, -1.7998e-01,\n",
       "        -1.0563e-02, -4.7850e-01,  4.8708e-01,  1.3187e-01,  1.5280e-01,\n",
       "         5.9422e-01,  5.1958e-01, -5.9279e-01,  2.2101e-01, -4.5308e-01,\n",
       "        -4.2458e-01, -1.5477e-01, -5.8748e-01,  1.1946e+00,  6.4572e-01,\n",
       "        -1.5644e+00,  5.7920e-01, -8.5573e-01, -1.0718e-01, -6.2623e-01,\n",
       "         6.1120e-02, -1.5988e-02,  1.1854e-01, -4.4646e-01, -2.1820e-01,\n",
       "        -5.2746e-01,  5.2397e-01,  3.0440e-01,  1.9963e-01,  1.7953e-01,\n",
       "        -5.2410e-01, -1.3095e+00, -5.4661e-01, -6.7623e-02, -3.2659e-01,\n",
       "         6.2480e-01,  1.0921e+00,  1.7148e-01, -2.4683e-01, -4.2535e-01,\n",
       "         4.0062e-01, -6.6125e-01,  2.5730e-01,  7.3834e-01,  3.6972e-01,\n",
       "        -4.1098e-01, -6.0694e-01, -2.2665e-01, -1.7545e-01,  2.8234e-01,\n",
       "         3.7415e-01,  8.8669e-01,  5.4998e-01,  3.9648e-01, -5.1426e-02,\n",
       "         1.7896e-01,  7.7354e-01,  3.7293e-01,  7.3963e-02,  2.0220e-01,\n",
       "         4.7986e-01, -1.1688e+00,  2.8498e-01,  1.6926e-02,  3.0373e-02,\n",
       "        -4.4044e-01, -1.5942e-01,  3.7650e-01,  4.4091e-01, -7.5443e-01,\n",
       "        -3.7062e-01, -6.9846e-01,  3.5699e-01,  3.2108e-01,  5.1764e-01,\n",
       "         6.5907e-02,  1.4349e+00, -2.2349e-01, -1.0700e+00,  7.0399e-01,\n",
       "         4.9790e-01,  1.0002e+00, -7.0727e-01,  1.5788e+00,  2.0540e-01,\n",
       "         1.1770e-01, -9.8545e-01, -3.3444e-01,  7.8798e-02,  5.4367e-01,\n",
       "        -2.3382e-01, -3.9838e-01,  2.2647e-01, -1.9887e-01, -3.7625e-01,\n",
       "        -2.2848e-01,  2.7345e-01,  4.5633e-01, -4.3127e-02,  6.7940e-02,\n",
       "        -3.9233e-01, -5.1668e-02, -5.4106e-01,  6.2419e-02, -5.4462e-01,\n",
       "        -7.6477e-01, -6.9236e-01,  8.4588e-02,  1.1287e+00, -1.1813e-01,\n",
       "        -1.2318e-01,  8.4411e-02,  5.3942e-01, -3.2158e-01, -3.2650e-01,\n",
       "         3.4123e-01, -1.4317e-01,  4.2040e-01, -2.4805e-01, -2.3667e-01,\n",
       "         4.6197e-01, -1.1903e+00,  4.2114e-01,  2.6619e-02, -1.4955e-01,\n",
       "         4.0301e-01, -2.0544e-01, -9.0981e-02, -1.7189e+00,  1.9669e-01,\n",
       "        -5.0372e-02, -3.2817e-01,  5.7730e-01,  4.7384e-01, -2.6612e-01,\n",
       "        -1.0843e+00,  4.3174e-01, -1.2538e-01, -2.4494e-01,  2.2667e-01,\n",
       "        -1.1383e+00, -3.7897e-01,  6.2069e-01,  1.2682e-01,  2.4115e-01,\n",
       "         1.2114e+00,  5.3143e-01, -5.8771e-02, -1.2244e-01, -6.5834e-01,\n",
       "        -1.0910e-01,  3.3561e-01, -1.2055e-01, -1.5717e-02, -1.3833e-01,\n",
       "         4.5711e-01, -4.0328e-02,  6.4034e-02,  4.8157e-01, -7.4477e-01,\n",
       "         2.3659e-01, -8.7088e-02,  9.1109e-01,  3.9360e-01, -4.7752e-01,\n",
       "        -8.1447e-01,  6.1921e-02, -9.4537e-02, -8.4355e-02, -3.6412e-02,\n",
       "        -2.4127e-01, -2.9186e-01, -1.7186e-01,  1.5424e-01,  3.4003e-01,\n",
       "        -8.9813e-01,  2.7284e-01, -4.3191e-01,  2.9340e-01, -1.5098e-01,\n",
       "        -8.6214e-02,  5.7220e-01,  1.4625e-01,  2.6030e-01,  1.5863e-01,\n",
       "         1.7424e-01,  3.1140e-02, -1.1036e-01, -3.6509e-01, -3.4314e-01,\n",
       "        -1.4061e-01,  8.3365e-01, -1.0370e-01, -6.1440e-01,  5.3209e-01,\n",
       "         4.7945e-01,  1.8429e-01,  1.9782e-02, -1.1209e+00, -6.1329e-01,\n",
       "        -3.6544e-01,  1.0812e+00, -1.0388e+00, -5.9484e-01,  3.2715e-01,\n",
       "        -8.2220e-01, -4.6737e-01,  2.4198e-01, -9.7681e-02, -3.3998e-01,\n",
       "        -5.7399e-01, -7.3166e-02,  6.8614e-01, -6.1533e-01,  7.1600e-01,\n",
       "        -1.5089e-01, -2.8306e-01, -3.6133e-01, -1.4880e-02,  2.4891e-01,\n",
       "        -1.2952e-01, -1.8842e-01,  2.1622e-01, -3.9364e-01,  9.1800e-02,\n",
       "        -4.1970e-01, -4.1853e-01,  5.6740e-01, -7.7805e-01,  9.5139e-01,\n",
       "        -3.0115e-01, -4.4050e-01, -6.3968e-01, -7.9211e-01,  2.5035e-01,\n",
       "         2.0600e-01, -6.1725e-01, -4.9821e-01,  1.1026e-01,  9.2629e-02,\n",
       "        -3.1156e-01, -1.0125e-01, -2.0008e-02, -2.4249e-01, -1.7580e-01,\n",
       "        -1.8337e-01, -2.3533e-01, -1.4510e+00,  2.1337e-01,  1.7782e-01,\n",
       "         2.9933e-01,  2.4431e-01,  3.1275e-01,  8.5692e-02,  3.6611e-01,\n",
       "         7.0515e-01, -7.6827e-01,  3.9713e-01,  5.3635e-01,  6.5506e-02,\n",
       "         2.4918e-01, -8.7947e-02,  9.0936e-02, -1.3155e-02,  5.9550e-01,\n",
       "        -9.1817e-02, -1.0154e-01, -5.4971e-03, -4.4386e-01,  3.3234e-01,\n",
       "        -9.5000e-01, -1.0439e+00,  1.0285e+00,  3.9362e-01,  3.3505e-01,\n",
       "         6.8131e-01,  9.0913e-01, -1.0015e+00,  3.0747e-01, -4.4956e-02,\n",
       "        -2.5595e-01, -4.0973e-01, -8.4746e-01, -3.8374e-02, -3.2303e-01,\n",
       "        -9.1559e-02, -7.2122e-01,  8.3990e-01, -1.5476e-01, -6.9103e-01,\n",
       "         6.8712e-01,  3.6075e-01,  6.2271e-01, -1.0622e-01, -4.0785e-01,\n",
       "         3.9065e-01,  4.0144e-01, -3.3867e-01, -1.2225e-02,  4.6688e-01,\n",
       "         3.7760e-01,  2.7077e-01, -4.0857e-01, -7.6106e-02, -5.8997e-01,\n",
       "         6.9964e-01,  9.6659e-02,  5.2779e-01, -4.4909e-01, -1.1898e+00,\n",
       "         7.3588e-02, -5.6519e-02,  4.2780e-01, -5.3873e-01, -4.0371e-01,\n",
       "         7.0556e-02,  2.0400e-01,  7.1189e-01,  6.5074e-01,  6.5836e-01,\n",
       "        -4.1973e-01, -3.9285e-01, -3.8642e-01,  6.4529e-02,  4.4893e-01,\n",
       "         8.8134e-01, -5.8815e-01,  1.1175e-01, -7.7898e-01, -2.3813e-01,\n",
       "         5.6348e-01, -3.9285e-01,  3.9348e-01, -9.8731e-02, -2.7727e-01,\n",
       "        -1.1585e+00, -2.6550e-01,  3.8362e-01, -6.8068e-01, -3.0023e-01,\n",
       "         5.8409e-01,  1.3553e-01,  2.8873e-02, -1.1846e-01, -7.3236e-01,\n",
       "         1.2700e-02,  1.9740e-01, -3.1068e-01, -3.0902e-01,  1.9277e-01,\n",
       "        -7.5304e-01, -9.5619e-01,  7.5179e-01,  4.6677e-01,  1.0253e-01,\n",
       "         1.6914e-01, -6.5535e-01,  1.3873e-01,  3.4068e-01, -1.6643e-01,\n",
       "         6.7836e-01, -5.1890e-01, -6.3778e-01, -1.5167e+00, -1.9709e-01,\n",
       "         6.8288e-01,  4.6010e-01,  2.3157e-01, -3.1566e-01, -9.0237e-01,\n",
       "         5.7985e-01, -9.8272e-02, -4.9824e-01,  3.6835e-01,  2.0503e-02,\n",
       "        -2.8039e-01,  5.6617e-01,  5.4069e-01,  9.2300e-01, -5.2697e-01,\n",
       "        -1.6182e-01, -5.6101e-01,  5.9831e-01,  7.8439e-01, -5.3372e-01,\n",
       "        -7.6944e-01,  8.0687e-01,  6.3860e-02, -6.6056e-01,  6.7079e-01,\n",
       "         2.0418e-02,  3.5392e-01, -8.7022e-02, -3.9140e-01,  8.2462e-01,\n",
       "         4.6656e-01,  8.9742e-01,  9.9763e-02, -4.7756e-01,  4.1245e-01,\n",
       "         3.9422e-01,  4.4000e-01,  1.5208e-01,  9.2963e-02, -2.2519e-01,\n",
       "        -1.8652e-01, -1.2580e+00,  7.0852e-01,  2.8042e-01, -7.4720e-01,\n",
       "        -5.1779e-01,  1.2376e+00, -5.0185e-01, -9.1068e-01,  6.1727e-01,\n",
       "         2.5755e-01,  2.0359e-01,  1.9757e-01, -7.6294e-01, -2.1485e-01,\n",
       "        -7.8670e-01,  4.7498e-02, -2.2992e-01, -7.1538e-01,  3.3307e-01,\n",
       "        -5.4547e-01,  5.8971e-01, -9.4961e-01,  1.5129e-01, -2.0570e-01,\n",
       "         1.0026e+00,  1.5957e-01,  3.4306e-01, -3.8254e-01, -9.2105e-02,\n",
       "        -1.7529e-01, -1.7725e+00, -8.9797e-03,  3.0677e-01,  3.6697e-02,\n",
       "        -6.4849e-01,  1.4606e-01,  5.9605e-01,  2.9399e-01, -1.9111e-01,\n",
       "         3.6598e-02, -1.0498e+00, -4.4319e-01,  5.6653e-01,  5.2952e-01,\n",
       "        -8.3631e-01, -8.0125e-01, -7.5322e-02, -9.1443e-02, -3.3864e-01,\n",
       "         3.6516e-01, -2.4054e-01, -2.7644e-01, -1.9038e-01,  3.9685e-02,\n",
       "         4.9656e-01,  3.8795e-02,  4.4537e-01,  4.5921e-02,  5.7647e-01,\n",
       "        -1.3107e+00, -2.2138e+00,  3.7265e-01,  7.4628e-01,  1.0129e-01,\n",
       "         1.8253e-01,  1.5136e-01, -3.2096e-01], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_with_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False,  True, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False,  True,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False,  True, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False, False,  True,\n",
      "        False, False, False, False, False, False, False,  True, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False,  True, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False,  True, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(out_with_pad == out_without_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(output.last_hidden_state.shape)\n",
    "print(output.pooler_output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
