{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code runs the huggingface baselines on our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "from pandas import read_parquet\n",
    "from transformers import BertModel\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForTokenClassification,BertTokenizerFast, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = read_parquet(r\"/home/javin/Coding/CSCI544/FinalProject/data/merge/raw.parquet\")\n",
    "data_dev = read_parquet(r\"/home/javin/Coding/CSCI544/FinalProject/data/merge/dev.parquet\")\n",
    "data_test = read_parquet(r\"/home/javin/Coding/CSCI544/FinalProject/data/merge/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>langs</th>\n",
       "      <th>spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[#, #, ユ, リ, ウ, ス, ・, ベ, ー, リ, ッ, ク, #, 1, 9, ...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, ...</td>\n",
       "      <td>[ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, j...</td>\n",
       "      <td>[PER: ユ リ ウ ス ・ ベ ー リ ッ ク]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[#, ル, ノ, ー, 、, 日, 産, 自, 動, 車, に, 資, 本, 参, 加, 。]</td>\n",
       "      <td>[0, 3, 4, 4, 0, 3, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, j...</td>\n",
       "      <td>[ORG: ル ノ ー, ORG: 日 産 自 動 車]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ソ, マ, リ, ラ, ン, ド, （, 事, 実, 上, 独, 立, し, た, 地, ...</td>\n",
       "      <td>[5, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, j...</td>\n",
       "      <td>[LOC: ソ マ リ ラ ン ド]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[R, E, D, I, R, E, C, T, #, ス, レ, イ, マ, ニ, エ, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, ...</td>\n",
       "      <td>[ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, j...</td>\n",
       "      <td>[ORG: ス レ イ マ ニ エ ・ モ, ORG: ス ク]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[#, ', ', E, l, e, c, t, r, i, c, #, C, o, u, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, j...</td>\n",
       "      <td>[PER: S t e v e, PER: R e i c h]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[', '', Mário, Jardel, '', ']</td>\n",
       "      <td>[0, 0, 1, 2, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es, es]</td>\n",
       "      <td>[PER: Mário Jardel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>[José, Joaquín, Araiza]</td>\n",
       "      <td>[1, 2, 2]</td>\n",
       "      <td>[es, es, es]</td>\n",
       "      <td>[PER: José Joaquín Araiza]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[', '', Poestenkill, '', ', ;, o]</td>\n",
       "      <td>[0, 0, 5, 0, 0, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es]</td>\n",
       "      <td>[LOC: Poestenkill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[REDIRECCIÓN, 1., Lig, 1976-77]</td>\n",
       "      <td>[0, 5, 6, 6]</td>\n",
       "      <td>[es, es, es, es]</td>\n",
       "      <td>[LOC: 1. Lig 1976-77]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[Real, Academia, de, las, Ciencias, de, Suecia]</td>\n",
       "      <td>[3, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[es, es, es, es, es, es, es]</td>\n",
       "      <td>[ORG: Real Academia de las Ciencias de Suecia]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "0     [#, #, ユ, リ, ウ, ス, ・, ベ, ー, リ, ッ, ク, #, 1, 9, ...   \n",
       "1      [#, ル, ノ, ー, 、, 日, 産, 自, 動, 車, に, 資, 本, 参, 加, 。]   \n",
       "2     [ソ, マ, リ, ラ, ン, ド, （, 事, 実, 上, 独, 立, し, た, 地, ...   \n",
       "3     [R, E, D, I, R, E, C, T, #, ス, レ, イ, マ, ニ, エ, ...   \n",
       "4     [#, ', ', E, l, e, c, t, r, i, c, #, C, o, u, ...   \n",
       "...                                                 ...   \n",
       "9995                      [', '', Mário, Jardel, '', ']   \n",
       "9996                            [José, Joaquín, Araiza]   \n",
       "9997                  [', '', Poestenkill, '', ', ;, o]   \n",
       "9998                    [REDIRECCIÓN, 1., Lig, 1976-77]   \n",
       "9999    [Real, Academia, de, las, Ciencias, de, Suecia]   \n",
       "\n",
       "                                               ner_tags  \\\n",
       "0     [0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, ...   \n",
       "1      [0, 3, 4, 4, 0, 3, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0]   \n",
       "2     [5, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 4, 4, 4, 4, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "9995                                 [0, 0, 1, 2, 0, 0]   \n",
       "9996                                          [1, 2, 2]   \n",
       "9997                              [0, 0, 5, 0, 0, 0, 0]   \n",
       "9998                                       [0, 5, 6, 6]   \n",
       "9999                              [3, 4, 4, 4, 4, 4, 4]   \n",
       "\n",
       "                                                  langs  \\\n",
       "0     [ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, j...   \n",
       "1     [ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, j...   \n",
       "2     [ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, j...   \n",
       "3     [ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, j...   \n",
       "4     [ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, ja, j...   \n",
       "...                                                 ...   \n",
       "9995                           [es, es, es, es, es, es]   \n",
       "9996                                       [es, es, es]   \n",
       "9997                       [es, es, es, es, es, es, es]   \n",
       "9998                                   [es, es, es, es]   \n",
       "9999                       [es, es, es, es, es, es, es]   \n",
       "\n",
       "                                               spans  \n",
       "0                         [PER: ユ リ ウ ス ・ ベ ー リ ッ ク]  \n",
       "1                       [ORG: ル ノ ー, ORG: 日 産 自 動 車]  \n",
       "2                                 [LOC: ソ マ リ ラ ン ド]  \n",
       "3                   [ORG: ス レ イ マ ニ エ ・ モ, ORG: ス ク]  \n",
       "4                   [PER: S t e v e, PER: R e i c h]  \n",
       "...                                              ...  \n",
       "9995                             [PER: Mário Jardel]  \n",
       "9996                      [PER: José Joaquín Araiza]  \n",
       "9997                              [LOC: Poestenkill]  \n",
       "9998                           [LOC: 1. Lig 1976-77]  \n",
       "9999  [ORG: Real Academia de las Ciencias de Suecia]  \n",
       "\n",
       "[120200 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(data_train)\n",
    "validation_ds = Dataset.from_pandas(data_dev)\n",
    "test_ds = Dataset.from_pandas(data_test)\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds['train'] = train_ds\n",
    "ds['validation'] = validation_ds\n",
    "ds['test'] = test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得tag文件\n",
    "with open(r\"/home/javin/Coding/CSCI544/FinalProject/data/merge/tags_2_idx.json\",\"r\") as file:\n",
    "    tags_2_idx = json.load(file)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_2_tags = {tags_2_idx[tag]:tag for tag in tags_2_idx.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 3: 'B-ORG',\n",
       " 4: 'I-ORG',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " 7: 'B-MISC',\n",
       " 8: 'I-MISC'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_2_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"Babelscape/wikineural-multilingual-ner\"\n",
    "\n",
    "wikineural_tokenizer = AutoTokenizer.from_pretrained(model_name, padding=\"max_length\",truncation = True,  is_split_into_words=True)\n",
    "wikineural_model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels = len(idx_2_tags), label2id = tags_2_idx, id2label = idx_2_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = wikineural_tokenizer(ds['train'][9996]['tokens'], truncation=True, is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101,  108,  122,  130,  130,  126, 3642, 1881, 3692, 4473, 8239, 2072,\n",
       "         5751, 5785,  102]], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "wikineural_input_token = torch.tensor([tokenized['input_ids']]).to(device)\n",
    "wikineural_input_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikineural_model= wikineural_model.to(device)\n",
    "model_prediction = wikineural_model(wikineural_input_token)\n",
    "model_logits = model_prediction.logits \n",
    "model_predictions = torch.argmax(model_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_map_predictions(original_tokens, tokenized_inputs, predictions):\n",
    "    # Assuming predictions are aligned with the tokenized input (subtokens)\n",
    "    word_ids = tokenized_inputs.word_ids()  # Get word IDs for all tokens in the batch\n",
    "    reversed_predictions = []\n",
    "    current_word_id = None\n",
    "    current_word_predictions = []\n",
    "    \n",
    "    for word_id, prediction in zip(word_ids, predictions):\n",
    "        if word_id is None:\n",
    "            # Skipping special tokens like [CLS], [SEP], etc.\n",
    "            continue\n",
    "        \n",
    "        if word_id != current_word_id:\n",
    "            # Encountering a new word, decide the label for the previous word\n",
    "            if current_word_predictions:\n",
    "                # You can implement different strategies here\n",
    "                # For simplicity, taking the first prediction for the word\n",
    "                reversed_predictions.append(current_word_predictions[0])\n",
    "            current_word_predictions = [prediction]\n",
    "            current_word_id = word_id\n",
    "        else:\n",
    "            # Accumulating predictions for subtokens of the same word\n",
    "            current_word_predictions.append(prediction)\n",
    "    \n",
    "    # Don't forget to add the prediction for the last word\n",
    "    if current_word_predictions:\n",
    "        reversed_predictions.append(current_word_predictions[0])\n",
    "\n",
    "    return [original_tokens, reversed_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#', '1', '9', '9', '5', '年', '、', '廣', '木', '隆', '一', '監', '督'],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_map_predictions(ds['train'][9996]['tokens'], tokenized, model_predictions[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][9996]['ner_tags']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci544finalproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
